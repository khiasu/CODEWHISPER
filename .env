# Flask Configuration
DEBUG=True
HOST=0.0.0.0
PORT=5000

# Ollama Configuration
OLLAMA_HOST=localhost
OLLAMA_PORT=11434
MODEL_NAME=codellama

# AI Model Parameters
TEMPERATURE=0.7
TOP_P=0.9
MAX_TOKENS=1000
REQUEST_TIMEOUT=30

# Validation Limits
MAX_CODE_LENGTH=10000
MIN_CODE_LENGTH=1
